{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "\n",
    "random.seed(999)\n",
    "torch.manual_seed(999)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/mnist_data\"\n",
    "\n",
    "WORKERS = 2\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "# Input Channels\n",
    "n_channels = 3\n",
    "\n",
    "# Latent Vector Size --> n-dimensional space from where random inputs are drawn from for the Generator\n",
    "n_z = 100\n",
    "\n",
    "# Number of Feature Maps/Channels for Generator\n",
    "ngf = 64\n",
    "\n",
    "# Number of Feature Maps/Channels for Discriminator\n",
    "ngd = 64\n",
    "\n",
    "# Number of Training Epochs\n",
    "epoch = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "# Beta 1 value for the Adam optimizer --> Controls how much of the previous running averages (1st Moment) are kept in current calculation\n",
    "b1 = 0.9\n",
    "\n",
    "# Beta 2 value for the Adam optimizer --> Controls how much of the squared previous running averages (2nd Moment) are kept in current calculation\n",
    "b2 = 0.999\n",
    "\n",
    "# Training Epochs\n",
    "epochs = 5\n",
    "\n",
    "# Number of times Discriminator's loss calculation is taken per iter\n",
    "n_critic = 5\n",
    "\n",
    "# Number of iterations per epoch\n",
    "n_iters = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(\n",
    "    root=path, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=WORKERS\n",
    ")\n",
    "\n",
    "\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Generator Class and Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=100, out_channels=512, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # Final out_channel is still 3 because the grayscale mnist images are represented using 3-channels (i.e same rgb values for all channels)\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    # Forward Loop of the Generator\n",
    "    def forward(self, input):\n",
    "        return self.model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Discriminator Class and Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=0),\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        rtn = self.model(input)\n",
    "        return torch.flatten(rtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating Generator\n",
    "G = Generator()\n",
    "G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating Discriminator\n",
    "D = Discriminator()\n",
    "D.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Optimizers to Use\n",
    "\n",
    "optim_D = torch.optim.Adam(D.parameters(), lr=lr[0], betas=(b1, b2))\n",
    "optim_G = torch.optim.Adam(G.parameters(), lr=lr[0], betas=(b1, b2))\n",
    "\n",
    "D.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "# Gradient Penalty Calculation for the Wasserstein Loss Calculation\n",
    "###################################################################\n",
    "\n",
    "def calculate_gradient_penalty(model, real_images, fake_images, device):\n",
    "    # Random weight term for interpolation between real and fake data\n",
    "    alpha = torch.randn((real_images.size(0), 1, 1, 1), device=device)\n",
    "    # Get random interpolation between real and fake data\n",
    "    interpolates = (alpha * real_images + ((1 - alpha) * fake_images)).requires_grad_(True)\n",
    "\n",
    "    model_interpolates = model(interpolates)\n",
    "    grad_outputs = torch.ones(model_interpolates.size(), device=device, requires_grad=False)\n",
    "\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=model_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = torch.mean((gradients.norm(2, dim=1) - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Start of Training Loop\n",
    "##############################################\n",
    "\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "D.train()\n",
    "G.train()\n",
    "\n",
    "# Start train PSNR model.\n",
    "print(f\"Training for {epochs} epochs\")\n",
    "\n",
    "fixed_noise = torch.randn(BATCH_SIZE, 100, 1, 1, device=device)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for i, data in progress_bar:\n",
    "        real_images = data[0].to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
    "\n",
    "        ##############################################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ##############################################\n",
    "        # Set discriminator gradients to zero.\n",
    "        D.zero_grad()\n",
    "\n",
    "        # Train with real\n",
    "        real_output = D(real_images)\n",
    "        errD_real = torch.mean(real_output)\n",
    "        D_x = real_output.mean().item()\n",
    "\n",
    "        # Generate fake image batch with G\n",
    "        fake_images = G(noise)\n",
    "\n",
    "        # Train with fake\n",
    "        fake_output = D(fake_images.detach())\n",
    "        errD_fake = torch.mean(fake_output)\n",
    "        D_G_z1 = fake_output.mean().item()\n",
    "\n",
    "        # Calculate W-div gradient penalty\n",
    "        gradient_penalty = calculate_gradient_penalty(model=D, real_images=real_images.data, fake_images=fake_images.data, device=device)\n",
    "\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = -errD_real + errD_fake + gradient_penalty * 10\n",
    "        errD.backward()\n",
    "        # Update D\n",
    "        optim_D.step()\n",
    "\n",
    "        # Train the generator every n_critic iterations\n",
    "        if (i + 1) % n_critic == 0:\n",
    "            ##############################################\n",
    "            # (2) Update G network: maximize log(D(G(z)))\n",
    "            ##############################################\n",
    "            # Set generator gradients to zero\n",
    "            G.zero_grad()\n",
    "\n",
    "            # Generate fake image batch with G\n",
    "            fake_images = G(noise)\n",
    "            fake_output = D(fake_images)\n",
    "            errG = -torch.mean(fake_output)\n",
    "            D_G_z2 = fake_output.mean().item()\n",
    "            errG.backward()\n",
    "            optim_G.step()\n",
    "\n",
    "            progress_bar.set_description(f\"[{epoch + 1}/{epochs}][{i + 1}/{len(dataloader)}] \"\n",
    "                                            f\"Loss_D: {errD.item():.6f} Loss_G: {errG.item():.6f} \"\n",
    "                                            f\"D(x): {D_x:.6f} D(G(z)): {D_G_z1:.6f}/{D_G_z2:.6f}\")\n",
    "            \n",
    "            G_losses.append(errG.item())\n",
    "            D_losses.append(errD.item())\n",
    "            \n",
    "        iters = i + epoch * len(dataloader) + 1\n",
    "        \n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = G(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        if iters == int(n_iters):  # If the iteration is reached, exit.\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
